import os
import pandas as pd
from langchain_community.document_loaders import GitLoader, GithubFileLoader, ReadTheDocsLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from sqlalchemy import all_

# === ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸURL ===
DOC_PATHS = [
    "https://docs.langchain.com/docs",
    "https://docs.langgraph.dev/docs"
]

GIT_REPOS = [
    "https://github.com/langchain-ai/langchain",
    "https://github.com/langchain-ai/langgraph"
]


# === GitHubã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ï¼†èª­ã¿è¾¼ã¿ ===
all_docs = []
for repo_url in GIT_REPOS:
    loader = GithubFileLoader(
        repo=repo_url,
        access_token=os.getenv("GITHUB_TOKEN"),
        branch="main",
        file_filter=lambda f: f.endswith(".md") or "README" in f or f.endswith(".py") or f.endswith(".ipynb") or f.endswith(".mdx"),
    )
    docs = loader.load()
    print(f"Loaded {len(docs)} documents from {repo_url}")
    # all_docs.extend(docs)
    all_docs.extend(docs)

# === åˆ†å‰² ===
print("ğŸ§© Splitting documents...")
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=100
)
split_docs = splitter.split_documents(all_docs)

# === prompt / completion ã«å¤‰æ› ===
print("ğŸ“„ Generating prompt/completion pairs...")
df = pd.DataFrame([
    {
        "prompt": f"ä»¥ä¸‹ã®æ–‡ç« ã‚’è¦ç´„ã—ã¦ãã ã•ã„:\n\n{doc.page_content}",
        "completion": doc.page_content
    }
    for doc in split_docs
])

# === JSONLã§ä¿å­˜ ===
df.to_json("train.jsonl", orient="records", lines=True)
print("âœ… train.jsonl ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆä»¶æ•°: {}ï¼‰".format(len(df)))